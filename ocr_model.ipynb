{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93a0de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers@82a06db03535c49aa987719ed0746a76093b1ec4\n",
      "  Cloning https://github.com/huggingface/transformers (to revision 82a06db03535c49aa987719ed0746a76093b1ec4) to /tmp/pip-req-build-t9cur_ga\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-t9cur_ga\n",
      "  Running command git rev-parse -q --verify 'sha^82a06db03535c49aa987719ed0746a76093b1ec4'\n",
      "  Running command git fetch -q https://github.com/huggingface/transformers 82a06db03535c49aa987719ed0746a76093b1ec4\n",
      "  Running command git checkout -q 82a06db03535c49aa987719ed0746a76093b1ec4\n",
      "  Resolved https://github.com/huggingface/transformers to commit 82a06db03535c49aa987719ed0746a76093b1ec4\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1.dev0) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1.dev0) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1.dev0) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1.dev0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1.dev0) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1.dev0) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1.dev0) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1.dev0) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1.dev0) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1.dev0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1.dev0) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1.dev0) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1.dev0) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1.dev0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1.dev0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1.dev0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1.dev0) (2025.11.12)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for transformers: filename=transformers-4.57.1.dev0-py3-none-any.whl size=12023110 sha256=b92e486243673a8b24e3045e9f36c89f311f96e71283764deace9c2ce3d938d0\n",
      "  Stored in directory: /root/.cache/pip/wheels/09/02/24/56cc406f4aecd878c51092831cd891578e7aaddcac47ca99c7\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.57.3\n",
      "    Uninstalling transformers-4.57.3:\n",
      "      Successfully uninstalled transformers-4.57.3\n",
      "Successfully installed transformers-4.57.1.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers@82a06db03535c49aa987719ed0746a76093b1ec4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12ba2ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.118.3)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.38.0)\n",
      "Requirement already satisfied: python-multipart in /usr/local/lib/python3.12/dist-packages (0.0.20)\n",
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
      "Collecting pdf2image\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.48.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.12.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pdf2image) (11.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi) (4.12.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (3.11)\n",
      "Downloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pyngrok, pdf2image\n",
      "Successfully installed pdf2image-1.17.0 pyngrok-7.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi uvicorn python-multipart pyngrok openpyxl pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "906b66d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HunyuanOCR processor and model (FP16)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1de6f2232c49f395fef5a6043bb9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/370 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b5c936c17b489aae8e13976153f05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21014c3f26fe4e96aad76feec8f82923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df96a830dccf4c6480f823365915b830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/146 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106a4bf2d7fe4da5a021b93af16bcfd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2854edea64fb4ac99b9a5f104e488930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85bf822151de4af19dc1f14fdfb74f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e603ec07a614fecb20fe3a527a46efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/462M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16525a8048347789c0fde6023a0a6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/453M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f65ae19e7e42b6b1653d2557a0abe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/638M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a24f009d8174323baa2befbac3eaca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['pad_token_id']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8af49578d6c4b469cc3514759de95bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630673d6603c4f7e9ac97b97cc7cb5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/205 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model & processor loaded successfully!\n",
      "Device: cuda\n",
      "Device map: {'': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CELL 2: Load HunyuanOCR Model\n",
    "# ============================================================================\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, HunYuanVLForConditionalGeneration\n",
    "\n",
    "# Model Configuration\n",
    "MODEL_NAME = \"tencent/HunyuanOCR\"\n",
    "MAX_IMAGE_SIDE = 1024\n",
    "MAX_NEW_TOKENS = 2000\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Loading HunyuanOCR processor and model (FP16)...\")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_NAME, use_fast=False)\n",
    "\n",
    "model = HunYuanVLForConditionalGeneration.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"eager\",\n",
    ")\n",
    "\n",
    "try:\n",
    "    model = model.to(dtype=torch.float16)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    model.gradient_checkpointing_enable()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"‚úÖ Model & processor loaded successfully!\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Device map: {getattr(model, 'hf_device_map', 'unknown')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb240f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OCR inference function ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: OCR Inference Function\n",
    "# ============================================================================\n",
    "def load_and_resize(img, max_size=MAX_IMAGE_SIDE):\n",
    "    \"\"\"Resize image if needed\"\"\"\n",
    "    if isinstance(img, str):\n",
    "        img = Image.open(img).convert(\"RGB\")\n",
    "    \n",
    "    w, h = img.size\n",
    "    scale = max(w, h) / float(max_size)\n",
    "    if scale > 1.0:\n",
    "        new_w, new_h = int(w / scale), int(h / scale)\n",
    "        img = img.resize((new_w, new_h), Image.LANCZOS)\n",
    "    return img\n",
    "\n",
    "def clean_repeated_substrings(text):\n",
    "    \"\"\"Remove repeated suffix patterns\"\"\"\n",
    "    n = len(text)\n",
    "    if n < 8000:\n",
    "        return text\n",
    "    for length in range(2, n // 10 + 1):\n",
    "        candidate = text[-length:]\n",
    "        count = 0\n",
    "        i = n - length\n",
    "        while i >= 0 and text[i:i + length] == candidate:\n",
    "            count += 1\n",
    "            i -= length\n",
    "        if count >= 10:\n",
    "            return text[:n - length * (count - 1)]\n",
    "    return text\n",
    "\n",
    "def run_ocr_inference(image_path):\n",
    "    \"\"\"Run OCR inference on a single image\"\"\"\n",
    "    try:\n",
    "        image = load_and_resize(image_path, max_size=MAX_IMAGE_SIDE)\n",
    "        \n",
    "        messages = [\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": \"\"},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image\", \"image\": image_path},\n",
    "                        {\"type\": \"text\", \"text\":\n",
    "                            (\n",
    "                               \"\"\"‚Ä¢ Identify the formula in the image and represent it using LaTeX format.\n",
    "\n",
    "                                  ‚Ä¢ Parse the table in the image into HTML.\n",
    "\n",
    "                                  ‚Ä¢ Parse the chart in the image; use Mermaid format for flowcharts and Markdown for other charts.\n",
    "\n",
    "                                  ‚Ä¢ Extract all information from the main body of the document image and represent it in markdown format. Tables should be expressed in HTML format, formulas in the document should be represented using LaTeX format, and the parsing should be organized according to the reading order.\"\"\"\n",
    "                            )\n",
    "                        }\n",
    "                    ],\n",
    "                }\n",
    "            ]\n",
    "        ]\n",
    "        \n",
    "        texts = [\n",
    "            processor.apply_chat_template(msg, tokenize=False, add_generation_prompt=True)\n",
    "            for msg in messages\n",
    "        ]\n",
    "        \n",
    "        inputs = processor(\n",
    "            text=texts,\n",
    "            images=[image],\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        model_device = next(model.parameters()).device\n",
    "        if \"pixel_values\" in inputs:\n",
    "            inputs[\"pixel_values\"] = inputs[\"pixel_values\"].to(dtype=torch.float16, device=model_device)\n",
    "        \n",
    "        for k, v in list(inputs.items()):\n",
    "            if k != \"pixel_values\":\n",
    "                try:\n",
    "                    inputs[k] = v.to(device=model_device)\n",
    "                except Exception:\n",
    "                    pass\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if DEVICE == \"cuda\":\n",
    "                with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                    generated_ids = model.generate(\n",
    "                        **inputs,\n",
    "                        max_new_tokens=MAX_NEW_TOKENS,\n",
    "                        do_sample=False,\n",
    "                        use_cache=True,\n",
    "                    )\n",
    "            else:\n",
    "                generated_ids = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=MAX_NEW_TOKENS,\n",
    "                    do_sample=False,\n",
    "                    use_cache=True,\n",
    "                )\n",
    "        \n",
    "        input_ids = inputs.get(\"input_ids\")\n",
    "        if input_ids is not None:\n",
    "            generated_trimmed = [out_ids[len(in_ids):] for in_ids, out_ids in zip(input_ids, generated_ids)]\n",
    "            decoded = processor.batch_decode(generated_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "        else:\n",
    "            decoded = processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "        \n",
    "        output_text = decoded[0] if isinstance(decoded, (list, tuple)) else str(decoded)\n",
    "        output_text = clean_repeated_substrings(output_text).strip()\n",
    "        \n",
    "        # Cleanup\n",
    "        del inputs, generated_ids\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return output_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå OCR Error: {repr(e)}\")\n",
    "        raise e\n",
    "\n",
    "print(\"‚úÖ OCR inference function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89223be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Excel converter function ready!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 4: Text to Excel Converter (Handles Markdown + HTML Tables)\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from io import BytesIO\n",
    "\n",
    "def clean_text_line(line):\n",
    "    \"\"\"Clean markdown formatting from text lines\"\"\"\n",
    "    line = re.sub(r'\\*\\*([^*]+)\\*\\*', r'\\1', line)\n",
    "    line = re.sub(r'\\*([^*]+)\\*', r'\\1', line)\n",
    "    line = re.sub(r'^#+\\s+', '', line)\n",
    "    return line.strip()\n",
    "\n",
    "def parse_markdown_table_rows(md_text):\n",
    "    \"\"\"Extract ONLY markdown table rows (no text lines)\"\"\"\n",
    "    rows = []\n",
    "    lines = md_text.split(\"\\n\")\n",
    "    \n",
    "    for line in lines:\n",
    "        if re.match(r\"^\\s*\\|.*\\|\\s*$\", line):\n",
    "            parts = [col.strip() for col in line.strip().split(\"|\")[1:-1]]\n",
    "            if all(re.match(r\"^:?-+:?$\", p.replace(\" \", \"\")) for p in parts):\n",
    "                continue\n",
    "            rows.append(parts)\n",
    "    \n",
    "    return rows\n",
    "\n",
    "def parse_html_tables(html_text):\n",
    "    \"\"\"Extract all HTML tables\"\"\"\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "    all_rows = []\n",
    "    \n",
    "    for table in soup.find_all(\"table\"):\n",
    "        for tr in table.find_all(\"tr\"):\n",
    "            cells = []\n",
    "            for td in tr.find_all([\"td\", \"th\"]):\n",
    "                text = td.get_text(strip=True)\n",
    "                colspan = int(td.get(\"colspan\", 1))\n",
    "                cells.append(text)\n",
    "                for _ in range(colspan - 1):\n",
    "                    cells.append(\"\")\n",
    "            if cells:\n",
    "                all_rows.append(cells)\n",
    "    \n",
    "    return all_rows\n",
    "\n",
    "def extracted_text_to_excel(extracted_text):\n",
    "    \"\"\"\n",
    "    Convert extracted text (markdown + HTML tables) to Excel bytes\n",
    "    Uses proven lab report conversion logic\n",
    "    \"\"\"\n",
    "    from openpyxl.styles import Font, Alignment, Border, Side\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    # Extract table rows separately\n",
    "    md_table_rows = parse_markdown_table_rows(extracted_text)\n",
    "    html_table_rows = parse_html_tables(extracted_text)\n",
    "    \n",
    "    # Add NON-TABLE TEXT FIRST\n",
    "    for line in extracted_text.split(\"\\n\"):\n",
    "        # Skip markdown table rows\n",
    "        if re.match(r\"^\\s*\\|.*\\|\\s*$\", line):\n",
    "            continue\n",
    "        \n",
    "        # Skip HTML table tags\n",
    "        if any(tag in line for tag in [\"<table\", \"</table\", \"<tr\", \"</tr\", \"<td\", \"</td\", \"<th\", \"</th\"]):\n",
    "            continue\n",
    "        \n",
    "        cleaned = clean_text_line(line)\n",
    "        if cleaned:\n",
    "            rows.append([cleaned])\n",
    "        elif line.strip() == \"\":\n",
    "            if rows and rows[-1] != [\"\"]:\n",
    "                rows.append([\"\"])\n",
    "    \n",
    "    # Add MARKDOWN TABLE ROWS\n",
    "    if md_table_rows:\n",
    "        rows.append([\"\"])\n",
    "        for table_row in md_table_rows:\n",
    "            rows.append(table_row)\n",
    "    \n",
    "    # Add HTML TABLE ROWS\n",
    "    if html_table_rows:\n",
    "        rows.append([\"\"])\n",
    "        for table_row in html_table_rows:\n",
    "            rows.append(table_row)\n",
    "    \n",
    "    # Clean up\n",
    "    while rows and rows[-1] == [\"\"]:\n",
    "        rows.pop()\n",
    "    \n",
    "    if not rows:\n",
    "        rows = [[\"No content extracted\"]]\n",
    "    \n",
    "    # Pad rows to same column count\n",
    "    max_cols = max(len(row) for row in rows)\n",
    "    padded_rows = [row + [\"\"] * (max_cols - len(row)) for row in rows]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(padded_rows).fillna(\"\")\n",
    "    \n",
    "    # Convert to Excel\n",
    "    excel_buffer = BytesIO()\n",
    "    with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:\n",
    "        df.to_excel(writer, index=False, header=False, sheet_name='OCR_Results')\n",
    "        \n",
    "        worksheet = writer.sheets['OCR_Results']\n",
    "        \n",
    "        thin_border = Border(\n",
    "            left=Side(style='thin'),\n",
    "            right=Side(style='thin'),\n",
    "            top=Side(style='thin'),\n",
    "            bottom=Side(style='thin')\n",
    "        )\n",
    "        \n",
    "        # Identify table rows\n",
    "        table_rows = set()\n",
    "        for idx, row in enumerate(padded_rows, 1):\n",
    "            non_empty = sum(1 for cell in row if str(cell).strip())\n",
    "            if non_empty > 1:\n",
    "                table_rows.add(idx)\n",
    "        \n",
    "        # Auto-adjust column widths\n",
    "        for column in worksheet.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            \n",
    "            for cell in column:\n",
    "                try:\n",
    "                    cell_value = str(cell.value)\n",
    "                    if cell_value and cell_value not in [\"nan\", \"\"]:\n",
    "                        max_length = max(max_length, len(cell_value))\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            adjusted_width = min(max(max_length + 2, 12), 50)\n",
    "            worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "        \n",
    "        # Apply formatting\n",
    "        for row_idx, row in enumerate(worksheet.iter_rows(), 1):\n",
    "            is_table_row = row_idx in table_rows\n",
    "            \n",
    "            for cell in row:\n",
    "                cell.alignment = Alignment(wrap_text=True, vertical='top', horizontal='left')\n",
    "                \n",
    "                if is_table_row and str(cell.value).strip():\n",
    "                    cell.border = thin_border\n",
    "                    \n",
    "                    if row_idx > 1 and (row_idx - 1) not in table_rows:\n",
    "                        cell.font = Font(bold=True)\n",
    "    \n",
    "    excel_buffer.seek(0)\n",
    "    return excel_buffer\n",
    "\n",
    "print(\"‚úÖ Excel converter function ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62037350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
      "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
      "Get:3 https://cli.github.com/packages stable InRelease [3,917 B]               \n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease                         \n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \n",
      "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,202 kB]\n",
      "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]           \n",
      "Get:8 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \n",
      "Get:9 https://cli.github.com/packages stable/main amd64 Packages [345 B]       \n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]     \n",
      "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease  \n",
      "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,532 kB] \n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\n",
      "Hit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease   \n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,410 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,961 kB]\n",
      "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,848 kB]\n",
      "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,287 kB]\n",
      "Get:20 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,623 kB]\n",
      "Get:21 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,185 kB]\n",
      "Fetched 38.0 MB in 5s (8,292 kB/s)                       \n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  poppler-utils\n",
      "0 upgraded, 1 newly installed, 0 to remove and 48 not upgraded.\n",
      "Need to get 186 kB of archives.\n",
      "After this operation, 697 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.12 [186 kB]\n",
      "Fetched 186 kB in 1s (181 kB/s)         \n",
      "Selecting previously unselected package poppler-utils.\n",
      "(Reading database ... 121689 files and directories currently installed.)\n",
      "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.12_amd64.deb ...\n",
      "Unpacking poppler-utils (22.02.0-2ubuntu0.12) ...\n",
      "Setting up poppler-utils (22.02.0-2ubuntu0.12) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee1eeef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PDF converter function ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: PDF to Images Converter\n",
    "# ============================================================================\n",
    "from pdf2image import convert_from_path\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "def pdf_to_images(pdf_path):\n",
    "    \"\"\"Convert PDF pages to images\"\"\"\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path, dpi=200)\n",
    "        image_paths = []\n",
    "        \n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        \n",
    "        for i, img in enumerate(images):\n",
    "            img_path = os.path.join(temp_dir, f\"page_{i+1}.jpg\")\n",
    "            img.save(img_path, 'JPEG')\n",
    "            image_paths.append(img_path)\n",
    "        \n",
    "        return image_paths, temp_dir\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå PDF conversion error: {repr(e)}\")\n",
    "        raise e\n",
    "\n",
    "print(\"‚úÖ PDF converter function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "472e40c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FastAPI app created!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: FastAPI Application\n",
    "# ============================================================================\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from fastapi.responses import StreamingResponse, JSONResponse\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import uuid\n",
    "\n",
    "app = FastAPI(title=\"HunyuanOCR API\")\n",
    "\n",
    "# Enable CORS for React frontend\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Temp directory for uploads\n",
    "UPLOAD_DIR = \"/content/uploads\"\n",
    "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
    "\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"status\": \"HunyuanOCR API is running!\", \"model\": MODEL_NAME}\n",
    "\n",
    "@app.post(\"/upload-and-process\")\n",
    "async def upload_and_process(file: UploadFile = File(...)):\n",
    "    \"\"\"\n",
    "    Upload image/PDF, run OCR, convert to Excel, return Excel file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate file type\n",
    "        file_ext = os.path.splitext(file.filename)[1].lower()\n",
    "        if file_ext not in [\".png\", \".jpg\", \".jpeg\", \".pdf\", \".bmp\", \".tiff\", \".tif\"]:\n",
    "            raise HTTPException(status_code=400, detail=\"Unsupported file type. Use PNG, JPG, PDF, BMP, or TIFF.\")\n",
    "        \n",
    "        # Save uploaded file\n",
    "        file_id = str(uuid.uuid4())\n",
    "        file_path = os.path.join(UPLOAD_DIR, f\"{file_id}{file_ext}\")\n",
    "        \n",
    "        with open(file_path, \"wb\") as f:\n",
    "            content = await file.read()\n",
    "            f.write(content)\n",
    "        \n",
    "        print(f\"üìÅ File saved: {file_path}\")\n",
    "        \n",
    "        # Process based on file type\n",
    "        all_extracted_text = []\n",
    "        temp_dirs_to_cleanup = []\n",
    "        \n",
    "        if file_ext == \".pdf\":\n",
    "            # Convert PDF to images\n",
    "            print(\"üìÑ Converting PDF to images...\")\n",
    "            image_paths, temp_dir = pdf_to_images(file_path)\n",
    "            temp_dirs_to_cleanup.append(temp_dir)\n",
    "            \n",
    "            # Run OCR on each page\n",
    "            for idx, img_path in enumerate(image_paths):\n",
    "                print(f\"üîç Processing page {idx + 1}/{len(image_paths)}...\")\n",
    "                extracted = run_ocr_inference(img_path)\n",
    "                all_extracted_text.append(f\"--- Page {idx + 1} ---\")\n",
    "                all_extracted_text.append(extracted)\n",
    "                all_extracted_text.append(\"\")\n",
    "            \n",
    "            combined_text = \"\\n\".join(all_extracted_text)\n",
    "        else:\n",
    "            # Process single image\n",
    "            print(\"üîç Processing image...\")\n",
    "            combined_text = run_ocr_inference(file_path)\n",
    "            print(\"=\"*60)\n",
    "            print(\"EXTRACTED TEXT:\")\n",
    "            print(combined_text)\n",
    "            print(\"=\"*60)\n",
    "        \n",
    "        # Convert to Excel\n",
    "        print(\"üìä Converting to Excel...\")\n",
    "        excel_buffer = extracted_text_to_excel(combined_text)\n",
    "        \n",
    "        # Cleanup\n",
    "        os.remove(file_path)\n",
    "        for temp_dir in temp_dirs_to_cleanup:\n",
    "            shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "        \n",
    "        print(\"‚úÖ Processing complete!\")\n",
    "        \n",
    "        # Return Excel file\n",
    "        return StreamingResponse(\n",
    "            excel_buffer,\n",
    "            media_type=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\",\n",
    "            headers={\n",
    "                \"Content-Disposition\": f\"attachment; filename={os.path.splitext(file.filename)[0]}_ocr_result.xlsx\"\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {repr(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health_check():\n",
    "    return {\"status\": \"healthy\", \"model_loaded\": model is not None}\n",
    "\n",
    "print(\"‚úÖ FastAPI app created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ac740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üåê NGROK PUBLIC URL:\n",
      "NgrokTunnel: \"https://8581a2fb9278.ngrok-free.app\" -> \"http://localhost:8000\"\n",
      "============================================================\n",
      "\n",
      "Use this URL in your React app!\n",
      "Example: fetch('NgrokTunnel: \"https://8581a2fb9278.ngrok-free.app\" -> \"http://localhost:8000\"/upload-and-process', ...)\n",
      "\n",
      "\n",
      "‚úÖ FastAPI server is running!\n",
      "üì° Access the API at: NgrokTunnel: \"https://8581a2fb9278.ngrok-free.app\" -> \"http://localhost:8000\"\n",
      "üìñ API docs at: NgrokTunnel: \"https://8581a2fb9278.ngrok-free.app\" -> \"http://localhost:8000\"/docs\n",
      "\n",
      "üî• Server is ready to accept requests!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [376]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "ERROR:    [Errno 98] error while attempting to bind on address ('0.0.0.0', 8000): [errno 98] address already in use\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-10' coro=<Server.serve() done, defined at /usr/local/lib/python3.12/dist-packages/uvicorn/server.py:69> exception=SystemExit(1)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 164, in startup\n",
      "    server = await loop.create_server(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1584, in create_server\n",
      "    raise OSError(err.errno, msg) from None\n",
      "OSError: [Errno 98] error while attempting to bind on address ('0.0.0.0', 8000): [errno 98] address already in use\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipython-input-2117229765.py\", line 31, in run_server\n",
      "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/main.py\", line 593, in run\n",
      "    server.run()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 67, in run\n",
      "    return asyncio_run(self.serve(sockets=sockets), loop_factory=self.config.get_loop_factory())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 396, in __wakeup\n",
      "    self.__step()\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 303, in __step\n",
      "    self.__step_run_and_handle_result(exc)\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 71, in serve\n",
      "    await self._serve(sockets)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 86, in _serve\n",
      "    await self.startup(sockets=sockets)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 174, in startup\n",
      "    sys.exit(1)\n",
      "SystemExit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ File saved: /content/uploads/b0ed4c93-4e7c-4c10-b137-a6e07228b593.jpg\n",
      "üîç Processing image...\n",
      "============================================================\n",
      "EXTRACTED TEXT:\n",
      "<table><tr><td>Sir</td><td>Ganga Ram</td><td>Hospital</td><td>Dr.</td><td>Raj Kamal</td><td>Agarwal</td></tr><tr><td>Sir</td><td>Ganga Ram</td><td>Hospital</td><td>Rajinder Nagar</td><td>Sr. Consultant</td><td>Sr. Consultant</td></tr><tr><td>New Delhi-110060, INDIA</td><td>Tel : +91-11-4225 4000</td><td></td><td></td><td>Dept. of Anesthesiology</td><td>Dept. of Anesthesiology</td></tr><tr><td>Medical Superintendent (Offig.)</td><td></td><td></td><td></td><td>Pain & Peri Operative Medicine</td><td>Pain & Peri Operative Medicine</td></tr><tr><td>Sir</td><td>Ganga Ram</td><td>Komet Hospital, 7,8, Pura Road</td><td></td><td>Mobile : +91 98101 52201</td><td>Mobile : +91 98101 52201</td></tr><tr><td>New Delhi-110005</td><td>Tel : +91-11-40099998, (D) 45009980</td><td></td><td></td><td colspan=\"2\">E-mail : kamalgarwal300@gmail.com</td></tr></table>\n",
      "\n",
      "TO WHOM IT MAY CONCERN\n",
      "\n",
      "As per ICMR guideline, the contact of\n",
      "\n",
      "COVID is cases should be put on HOME\n",
      "\n",
      "ISOLATION even with Mild Symptom\n",
      "\n",
      "It is advised that everybody takes these\n",
      "\n",
      "preventive medication apart from following\n",
      "\n",
      "SOCIAL DISTANCING, HAND HYGIENE & WEARING\n",
      "\n",
      "MASK\n",
      "\n",
      "Rx\n",
      "\n",
      "TAB HYDROXY CHLOROQUINE 400mg once a week\n",
      "\n",
      "TAB ViTAMIN C one gram once a day\n",
      "\n",
      "TAB 2ING 50 mg once a day\n",
      "\n",
      "In case of fever\n",
      "\n",
      "TAB CROCIN / CALPOL 650 mg SOS\n",
      "\n",
      "In case of throat pain & cough\n",
      "\n",
      "TAB CETRIZINE 10mg once a day\n",
      "\n",
      "SYSRUP ALEX 2/3 Tea spoon 3 times a day\n",
      "\n",
      "DEPT. OF ANAESTHSILOGY\n",
      "\n",
      "PERIOOPERATIVE MEDICINE & PAIN\n",
      "\n",
      "SIR GANGARAM NEW DELHI-110060\n",
      "\n",
      "CHIGNER NAGAR\n",
      "\n",
      "PH: 09010152201\n",
      "============================================================\n",
      "üìä Converting to Excel...\n",
      "‚úÖ Processing complete!\n",
      "INFO:     39.62.194.174:0 - \"POST /upload-and-process HTTP/1.1\" 200 OK\n",
      "üìÅ File saved: /content/uploads/492cf8ef-9f2d-40bc-9592-4f77a6fb5aa2.jpg\n",
      "üîç Processing image...\n",
      "============================================================\n",
      "EXTRACTED TEXT:\n",
      "<table><tr><td>Dr.Naveen Polavarapu</td></tr><tr><td>MRCP (UK), FRCP (Gastro), CCT (Gastro), Liver Transplant Fellowship Consultant Gastroenterologist and Transplant Hepatologist Regd. No. 46206 P. 040-2360 7777. Ext 4005/1142 For appointments call between 10 am. 6 pm: 7382778899 Email: docpolav@gmail.com.</td></tr></table>\n",
      "\n",
      "# 24/8/21\n",
      "\n",
      "# To whom so ever it may concern\n",
      "\n",
      "This is to inform that Mr. Ch. SAMUEL City / Male is currently admitted under my care with IP. No: 367588.\n",
      "\n",
      "The is currently undergoing tealination on 8.00 for severe sepsis with MODS (likely levi's abscess with aspiration pneumonia ). The further needs hospital stay for about 8-10 days for complete recovery. This is to inform and kindly do the needful.\n",
      "\n",
      "# Thank you\n",
      "\n",
      "# A\n",
      "\n",
      "# Dr. NAVEEN POLAVARAPU\n",
      "MRCP (UK), MRCP (Gastro), MRCP (Gastro), COST (Gastro), Liver Transplant Fellowship Consultant Transplant Hepatologist Regd. No. 46206 Apollo Hospitals, Jubilee Hills, Hyd-96.\n",
      "\n",
      "OPPO A52\n",
      "\n",
      "Apollo Health City Campus, Jubilee Hills, Hyderabad 500 096, India. 91-1860 258 1066 Fax: +91-40-23608050. apollohealthcity.com www.apollohealthcity.com apollohealthcity apollohealthhyyd\n",
      "============================================================\n",
      "üìä Converting to Excel...\n",
      "‚úÖ Processing complete!\n",
      "INFO:     39.62.194.174:0 - \"POST /upload-and-process HTTP/1.1\" 200 OK\n",
      "\n",
      "üõë Server stopped!\n"
     ]
    },
    {
     "ename": "PyngrokNgrokURLError",
     "evalue": "ngrok client exception, URLError: [Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2117229765.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[1;32m   1345\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
      "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1338\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1383\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1332\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http.client.connect\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m         self.sock = self._create_connection(\n\u001b[0m\u001b[1;32m   1004\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n",
      "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mExceptionGroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"create_connection failed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m         \u001b[0mresponse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    533\u001b[0m                                   '_open', req)\n",
      "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 111] Connection refused>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPyngrokNgrokURLError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2117229765.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüõë Server stopped!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpublic_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mdisconnect\u001b[0;34m(public_url, pyngrok_config)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpublic_url\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_current_tunnels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mget_tunnels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;31m# One more check, if the given URL is still not in the list of tunnels, it is not active\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mget_tunnels\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0m_current_tunnels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m     for tunnel in api_request(f\"{api_url}/api/tunnels\", method=\"GET\",\n\u001b[0m\u001b[1;32m    422\u001b[0m                               timeout=pyngrok_config.request_timeout)[\"tunnels\"]:\n\u001b[1;32m    423\u001b[0m         \u001b[0mngrok_tunnel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNgrokTunnel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtunnel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpyngrok_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n\u001b[1;32m    597\u001b[0m                                     status_code, e.reason, e.headers, response_data)\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mPyngrokNgrokURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ngrok client exception, URLError: {e.reason}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPyngrokNgrokURLError\u001b[0m: ngrok client exception, URLError: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 7: Start FastAPI with Ngrok\n",
    "# ============================================================================\n",
    "from pyngrok import ngrok\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from threading import Thread\n",
    "\n",
    "# Allow nested event loops (needed for Colab)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Set your ngrok auth token (get from https://dashboard.ngrok.com/get-started/your-authtoken)\n",
    "# Replace 'YOUR_NGROK_AUTH_TOKEN' with your actual token\n",
    "NGROK_AUTH_TOKEN = \"enter your ngrok key\"  # ‚ö†Ô∏è REPLACE THIS!\n",
    "\n",
    "if NGROK_AUTH_TOKEN != \"YOUR_NGROK_AUTH_TOKEN\":\n",
    "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "\n",
    "# Start ngrok tunnel\n",
    "public_url = ngrok.connect(8000)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üåê NGROK PUBLIC URL:\")\n",
    "print(public_url)\n",
    "print(\"=\"*60)\n",
    "print(\"\\nUse this URL in your React app!\")\n",
    "print(\"Example: fetch('\" + str(public_url) + \"/upload-and-process', ...)\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Run FastAPI server\n",
    "def run_server():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
    "\n",
    "server_thread = Thread(target=run_server, daemon=True)\n",
    "server_thread.start()\n",
    "\n",
    "print(\"‚úÖ FastAPI server is running!\")\n",
    "print(\"üì° Access the API at:\", public_url)\n",
    "print(\"üìñ API docs at:\", str(public_url) + \"/docs\")\n",
    "print(\"\\nüî• Server is ready to accept requests!\")\n",
    "\n",
    "# Keep the cell running\n",
    "import time\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nüõë Server stopped!\")\n",
    "    ngrok.disconnect(public_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
